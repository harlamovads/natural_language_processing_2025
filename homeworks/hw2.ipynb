{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8da553",
   "metadata": {},
   "source": [
    "# Домашнее задание 2\n",
    "\n",
    "**ФИО:** \n",
    "\n",
    "**Дедлайн:** 19 декабря в 23:59\n",
    "\n",
    "*Допустимо привысить дедлайн на два дня и сдавать до 21 декабря в 23:59. Это никак не будет наказываться, но сдать ДЗ после этого времени будет нельзя*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66606dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets==3.6.0 peft accelerate evaluate seqeval scikit-learn matplotlib seaborn conllu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435610ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PrefixTuningConfig\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сиды для воспроизводимости результатов\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ad31d",
   "metadata": {},
   "source": [
    "## Задание 1 (4 балла)\n",
    "\n",
    "Начнём с классической задачи классификации. Вам предстоит поработать с датасетом [CoLA](https://huggingface.co/datasets/nyu-mll/glue) (Corpus of Linguistic Acceptability), который используется для проверки способности модели отличать грамматически верные предложения от неверных. В качестве базовой модели возьмите `bert-base-uncased`.\n",
    "\n",
    "Нужно провести два эксперимента по дообучению и сравнить их результаты:\n",
    "\n",
    "1.  **Полное дообучение.** Обучите модель целиком на полном тренировочном наборе данных.\n",
    "2.  **LoRA.** Обучите только адаптеры LoRA, также используя полный тренировочный набор.\n",
    "\n",
    "**Требования к эксперименту:**\n",
    "\n",
    "  * Обучайте модели как минимум 3 эпохи (можно больше, так как датасет небольшой и учится быстро).\n",
    "  * Используйте валидационную выборку для оценки качества. Основные метрики здесь — [Matthews Correlation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) и Accuracy. По желанию можно репортить и другие, например, F1-score.\n",
    "\n",
    "**Анализ результатов:**\n",
    "\n",
    "После обучения обеих моделей постройте графики или выведите сводную таблицу, где будут видны время обучения, количество обучаемых параметров и итоговое качество на валидации.\n",
    "\n",
    "Ответьте на вопросы:\n",
    "\n",
    "  * Насколько сильно отличается время обучения? Опционально можете сравнить потребления видеопамяти в момент обучения (можно посмотреть в Колабе)\n",
    "  * Сильно ли уступает (или выигрывает) LoRA по качеству полной модели?\n",
    "  * Как вы думаете, в каких ситуациях оправдано использование полного дообучения для таких задач, а в каких хватит адаптера?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1ed2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5afde46b",
   "metadata": {},
   "source": [
    "## Задание 2 (4 балла)\n",
    "\n",
    "В этом задании мы попытаемся выяснить, насколько хорошо лингвистические знания переносятся между разными языками. Для этого мы будем использовать задачу POS-теггинга (определение частей речи) и многоязычную модель `bert-base-multilingual-cased` (mBERT). С точки зрения машинного обучения мы решаем задачу классификации токенов (token classification), то есть назначаем класс для каждого слова в предложении, как в NER.\n",
    "\n",
    "Суть эксперимента: вы обучаете модель определять части речи только на английском языке, а затем тестируете её качество на немецком языке (Zero-shot transfer). Модель никогда не видела размеченных немецких данных в процессе обучения.\n",
    "\n",
    "Вам снова нужно реализовать два подхода:\n",
    "\n",
    "1.  **Полное дообучение** mBERT на английском датасете.\n",
    "2.  **LoRA** для mBERT на английском датасете.\n",
    "\n",
    "**Важное примечание по данным:**\n",
    "\n",
    "Мы будем использовать датасеты `universal_dependencies`. Чтобы не скачивать CONLL-U-файлы вручную и не приводить их к нужному формату, можно загрузить их в `datasets` с помощью уже подготовленных скриптов. Для этого версия библиотеки должна быть не выше 3.6.0, в более поздних версиях загрузка датасетов с помощью удалённых скриптов уже не работает. Также нужна библиотека `conllu`. Если вы запускали ячейку с установкой в начале тетрадки, там это уже учтено.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_english = load_dataset(\n",
    "    \"universal_dependencies\",\n",
    "    \"en_ewt\",\n",
    "    trust_remote_code=True)\n",
    "ud_german = load_dataset(\n",
    "    \"universal_dependencies\",\n",
    "    \"de_gsd\",\n",
    "    trust_remote_code=True)\n",
    "\n",
    "ud_english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5171a",
   "metadata": {},
   "source": [
    "**Требования к эксперименту:**\n",
    "\n",
    "  * Обучите обе версии модели на английских данных (минимум 3 эпохи).\n",
    "  * Проверьте качество на английских валидационных данных.\n",
    "  * Проверьте качество на немецком тестовом наборе (это и есть zero-shot).\n",
    "  * Для оценки используйте F1-score и Accuracy.\n",
    "\n",
    "**Анализ результатов:**\n",
    "\n",
    "Сравните результаты английского и немецкого языков для обоих подходов. Ответьте на вопросы:\n",
    "\n",
    "  * Насколько сильно падает качество при переходе на другой язык?\n",
    "  * Есть ли разница в способности переносить знания между полной моделью и LoRA? Кто лучше справился с переносом?\n",
    "  * Почему вообще этот перенос возможен? Какие лингвистические категории являются универсальными, а какие специфичны для языка, и как это влияет на результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86825b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b3b4a65",
   "metadata": {},
   "source": [
    "## Задание 3\\* (2 балла)\n",
    "\n",
    "Здесь мы заглянем внутрь \"черного ящика\" и попробуем понять, что происходит с весами модели во время обучения в первых двух заданиях. Его удобно выполнять параллельно с первыми двумя.\n",
    "\n",
    "**Что нужно сделать:**\n",
    "\n",
    "1.  **Анализ весов.** Вам необходимо написать функцию для расчета Евклидова расстояния между весами исходной предобученной модели и весами дообученной модели. Нас интересует не просто одно число, а изменение весов на разных уровнях архитектуры. Эта функция должна принимать на вход исходную модель, дообученную модель и (опционально) имена слоёв, между которыми мы хотим посчитать разницу. Если имена слоёв отсутствуют, возвращаем среднее расстояние между всеми соответствующими слоями двух моделей, если есть конкретные слои — разницу только для указанных слоёв.\n",
    "\n",
    "    Посчитайте расстояние между исходным и конечным состоянием для следующих компонентов:\n",
    "\n",
    "      * Слой эмбеддингов.\n",
    "      * Первый слой энкодера (нижний уровень).\n",
    "      * Средний слой энкодера.\n",
    "      * Последний слой энкодера (верхний уровень).\n",
    "      * Слой классификатора (голова).\n",
    "\n",
    "    Сделайте это сравнение для всех четырех моделей из предыдущих заданий (CoLA Full, CoLA LoRA, POS Full, POS LoRA). Для LoRA берите объединённую модель (база + адаптер), сравнивайте с базой. Можно построить гистограммы расстояний по слоям.\n",
    "\n",
    "2.  **Кривые обучения (Learning Curves):**\n",
    "\n",
    "    Визуализируйте графики потерь (loss) на тренировке и валидации по шагам или эпохам. Сравните динамику сходимости для полной модели и LoRA. Для этого вам может потребоваться увеличить количество эпох при обучении и сохранять метрики не каждую эпоху, а каждые *n* шагов.\n",
    "\n",
    "**Ответьте на вопросы:**\n",
    "\n",
    "  * Правда ли, что при дообучении основные изменения происходят только в верхних слоях трансформера? Подтверждают ли это ваши цифры?\n",
    "  * Есть ли разница в распределении изменений весов между задачей классификации предложений (CoLA) и классификации токенов (POS)?\n",
    "  * Почему слой классификатора (голова) обычно меняется сильнее всего?\n",
    "  * Если смотреть на кривые обучения, есть ли смысл увеличивать количество эпох? Видите ли вы признаки переобучения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76ca75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d17caf",
   "metadata": {},
   "source": [
    "## Расскажите нам, что думаете об этой домашке\n",
    "\n",
    "Как вам задания? Насколько интересно? Насколько сложно? Что хотелось бы добавить, изменить или убрать? Только честно! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78c9476",
   "metadata": {},
   "source": [
    "# Домашнее задание 1: LLM Usage\n",
    "\n",
    "**ФИО:** \n",
    "\n",
    "**Дедлайн:** 3 декабря в 23:59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c3bb6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Для выполнения задания мы дадим вам ключи для API провайдеров (OpenAI, DeepSeek, Together AI). Они привязаны к аккаунтам с фиксированным балансом. Если вы будете слать очень много запросов, в том числе и в цикле, или очень большие по длине запросы, деньги закончатся у всей группы, и никто не сможет доделать домашку. Мы, конечно, что-нибудь придумаем, но лучше этого не допускать :) Поэтому не размечайте/генерируйте большое количество примеров и не запускайте запросы по API в цикле (это не относится к последнему заданию, где вам надо работать с локальной моделькой в Колабе).\n",
    "\n",
    "**Не публикуйте ключи**. Никогда не вставляйте ключ прямым текстом в ячейку с кодом, если планируете кому-то показывать тетрадку или выкладывать её на публичный GitHub (и если не планируйте, лучше тоже не вставляйте — хорошие практики кода лучше усваивать сразу).\n",
    "\n",
    "* В Google Colab используйте вкладку \"Secrets\" (ключик слева).\n",
    "* При локальном запуске используйте файл `.env` и библиотеку `python-dotenv`. Пример файла `.env` есть в репо, можете просто переименовать `.env.example` в `.env` и вставить ключи.\n",
    "\n",
    "В ячейках ниже настроена загрузка ключей в зависимости от того, где вы запускаете код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade tiktoken openai python-dotenv transformers accelerate bitsandbytes -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111afc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для Google Colab\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
    "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если запускаете тетрадку у себя\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')\n",
    "TOGETHER_API_KEY = os.getenv('TOGETHER_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API-эндпойнты для DeepSeek и Together AI\n",
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com\"\n",
    "TOGETHER_BASE_URL = \"https://api.together.xyz/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b3ba9",
   "metadata": {},
   "source": [
    "## Задание 1. Токенизация (2 балла)\n",
    "\n",
    "Как мы обсуждали на семинаре, LLM видят текст не по буквам или словам, а по токенам. Для английского языка 1 токен — это часто целое слово, а для других языков (особенно с отличной от латиницы письменностью) одно слово может распадаться на несколько токенов. Поскольку API обычно тарифицируются за токены, работа с некоторыми языками может быть дороже и медленнее, да и перформанс моделек зависит от эффективности токенизации.\n",
    "\n",
    "1. Найдите три текста на разных языках.\n",
    "    * Тексты должны быть примерно одинаковыми по объёму (например, одна и та же новость или статья из Википедии, или просто три куска текста длиной не менее нескольких абзацев каждый).\n",
    "    * Языки должны быть непохожи друг на друга и на английский. Можно брать языки с отличающимися письменностями (например: кириллица, латиница, иероглифы, арабская письменность, грузинский и т.д.), а можно и с одной, но из разных семей. *Обоснуйте свой выбор языков в комментарии*.\n",
    "2. Выберите один токенизатор: либо `tiktoken` (токенизатор для моделей OpenAI), либо токенизатор любой открытой модели (например, Qwen или Llama — их можно загрузить через `transformers`.\n",
    "3. Для каждого текста посчитайте количество символов. Затем токенизируйте и посчитайте количество токенов. Вычислите отношение `Tokens / Characters`.\n",
    "4. Сделайте вывод. Какой язык токенизируется эффективнее всего, а какой самый неэффективный? Предположите, почему результат именно такой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d48ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41cf4680",
   "metadata": {},
   "source": [
    "## Задание 2. Синтетический датасет (2 балла)\n",
    "\n",
    "LLM'ки часто используют для создания датасетов. Представьте ситуацию: вам нужно сделать модельку кластеризации или классификации для задачи разрешения лексической многозначности (Word Sense Disambiguation). Размечать тысячи примеров вручную — долго и дорого, поэтому хорошей идеей будет попросить модель сгенерировать синтетический датасет, который потом можно валидировать.\n",
    "\n",
    "Сгенерируйте набор из 5 пар предложений с омонимами на русском языке. В каждой паре должно быть одно и то же слово, употреблённое в разных (двух) значениях (например, «ключ от двери» и «ключ — родник»). Для простоты примем, что мы рассматриваем только два любых значения для каждого слова, и для каждого нужно по одному предложению.\n",
    "\n",
    "LLM'ка должна отдать результат в формате JSON. Структура может быть любой удобной для вас, но она должна быть валидной и машиночитаемой. Примерная схема может выглядеть так (но вы можете придумать любую другую):\n",
    "\n",
    "```json\n",
    "{\"homonyms\": [\n",
    "  {\n",
    "    \"word\": \"коса\",\n",
    "    \"meanings\": [\n",
    "      {\n",
    "        \"definition\": \"Сельскохозяйственный инструмент\",\n",
    "        \"sentence\": \"Острая коса легко срезала высокую траву на лугу.\"\n",
    "      },\n",
    "      {\n",
    "        \"definition\": \"Вид укладки волос\",\n",
    "        \"sentence\": \"Девушка заплела длинную русую косу.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  ...\n",
    "]}\n",
    "```\n",
    "\n",
    "Проведите два эксперимента:\n",
    "\n",
    "1.  С **закрытой моделью** (например, `gpt-5.1` или `gpt-5-mini`).\n",
    "2.  С **открытой моделью**: например, `deepseek-chat` или любой другой семейства Qwen или Gemma через Together AI API. Можно использовать что-то из свежего: `Qwen/Qwen3-Next-80B-A3B-Instruct`, `Qwen/Qwen3-235B-A22B-Instruct-2507-tput` или маленькие модели, вроде `Qwen/Qwen2.5-14B-Instruct` (или даже 7B) или `google/gemma-3-4b-it`.\n",
    "\n",
    "Можете дать модели список из пяти омонимичных слов, тогда ей нужно будет только определить значения и придумать примеры, а можете не подсказывать и посмотреть, какие слова предложит сама модель — так интереснее!\n",
    "\n",
    "Для получения чистого JSON вы можете просто попросить модель не писать лишнего текста, кроме JSON (возможно, придётся убирать знаки начала и конца блока кода), либо, если интересно понять, как делать профессионально, разобраться со [structured output](https://platform.openai.com/docs/guides/structured-outputs) или более простым, но устаревшим и не всеми поддерживаемым [JSON output](https://api-docs.deepseek.com/guides/json_mode)\n",
    "\n",
    "В конце сравните результаты и сделайте выводы. Какая модель лучше справилась с подбором омонимов и/или примеров? Были ли трудности заставить модель отвечать в нужном формате? Были ли галлюцинации в значениях слов?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8d150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9a274b3",
   "metadata": {},
   "source": [
    "## Задание 3. Перевод (4 балла)\n",
    "\n",
    "В этом задании мы посмотрим, как параметры генерации и промпт-инжиниринг влияют на качество перевода.\n",
    "\n",
    "Выберите текст на каком-нибудь иностранном языке, отличном от английского (только не очень большой). Это может быть французский, немецкий, финский или любой другой, но желательно не очень популярный, чтобы задачка была поинтереснее (например, малый язык, если вы знаете какой-нибудь).\n",
    "\n",
    "Вам нужно перевести этот текст на русский язык, используя две модели: одну проприетарную и одну открытую.\n",
    "\n",
    "Для каждой из двух моделей проведите три эксперимента:\n",
    "\n",
    "1.  **Набор гиперпараметров 1.** Выберите параметры `temperature` и `top_p` (какой-то один или комбинацию, на ваше усмотрение, например, высокую температуру для большей креативности).\n",
    "2.  **Набор гиперпараметров 2.** Измените параметры (например, сделайте генерацию более детерминированной).\n",
    "3.  **Лучшие настройки + Промпт-инжиниринг.** Возьмите тот набор параметров из двух предыдущих, который показал лучший результат, и попробуйте улучшить качество с помощью изменения промпта. Выберите один из способов:\n",
    "      * *Few-shot:* добавьте в контекст несколько примеров удачного перевода с этого языка.\n",
    "      * *Error Correction:* добавьте в промпт указания на ошибки, которые модель допустила в предыдущих попытках (например, «не переводи названия буквально» или «сохраняй официальный стиль»). Может быть хорошей идеей добавить правильный перевод имён или специфических терминов, если они есть у вас в тексте.\n",
    "\n",
    "Итого у вас должно получиться 6 вариантов перевода (2 модели × 3 эксперимента).\n",
    "\n",
    "Выведите результаты всех экспериментов. Ответьте на вопросы:\n",
    "\n",
    "  * Какая модель справилась лучше?\n",
    "  * Как изменение гиперпараметров повлияло на текст? Стал ли он точнее, литературнее или, наоборот, начал разваливаться?\n",
    "  * Помогло ли усложнение промпта в третьем эксперименте улучшить итоговый результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc7a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0ecfcf1",
   "metadata": {},
   "source": [
    "## Задание 4\\*. Классификация (2 балла)\n",
    "\n",
    "В этом задании вам нужно будет запустить LLM'ку локально (в Google Colab) и проверить, как она справляется с задачей определения грамматичности предложений на русском языке.\n",
    "\n",
    "Мы будем использовать датасет [RuCoLA](https://huggingface.co/datasets/RussianNLP/rucola) (Russian Corpus of Linguistic Acceptability). Это набор предложений, часть из которых грамматически верные (Acceptable, класс 1), а часть — содержат ошибки (Unacceptable, класс 0). Ошибки могут быть разными: от нарушения согласования до галлюцинаций моделей.\n",
    "\n",
    "В оригинальном бенчмарке RuCoLA тестовый сет не содержит лейблов, а валидационный разбит на `in_domain` (примеры из лингвистических публикаций) и `out_of_domain` (генерация нейросетей). Мы будем использовать **in\\_domain**, потому что он понятнее и чище.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71433797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7869, 5)\n",
      "Dev shape: (983, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Иван вчера не позвонил.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>У многих туристов, кто посещают Кемер весной, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Syntax</td>\n",
       "      <td>USE8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Лесные запахи набегали волнами; в них смешалос...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USE5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Вчера президент имел неофициальную беседу с ан...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Seliverstova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Коллега так и не признал вину за катастрофу пе...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Testelets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence  acceptable  \\\n",
       "0   0                            Иван вчера не позвонил.           1   \n",
       "1   1  У многих туристов, кто посещают Кемер весной, ...           0   \n",
       "2   2  Лесные запахи набегали волнами; в них смешалос...           1   \n",
       "3   3  Вчера президент имел неофициальную беседу с ан...           1   \n",
       "4   4  Коллега так и не признал вину за катастрофу пе...           1   \n",
       "\n",
       "  error_type detailed_source  \n",
       "0          0   Paducheva2013  \n",
       "1     Syntax            USE8  \n",
       "2          0            USE5  \n",
       "3          0    Seliverstova  \n",
       "4          0       Testelets  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_url = \"https://huggingface.co/datasets/RussianNLP/rucola/resolve/main/data/in_domain_train.csv\"\n",
    "dev_url = \"https://huggingface.co/datasets/RussianNLP/rucola/resolve/main/data/in_domain_dev.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_url)\n",
    "df_dev = pd.read_csv(dev_url)\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Dev shape: {df_dev.shape}\")\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e962ee9",
   "metadata": {},
   "source": [
    "**Что нужно сделать:**\n",
    "\n",
    "1.  **Подготовка данных.** Из валидационной выборки возьмите случайные 50–100 примеров (это будет наш тест). Не берите сильно больше, иначе вы будете ждать результатов очень долго — инференс в Колабе небыстрый.\n",
    "      * *Важно:* Убедитесь, что в вашей выборке присутствуют оба класса (и 0, и 1), желательно поровну.\n",
    "2.  **Выбор модели.** Вам нужно выбрать и загрузить одну Instruct-модель, которая влезет в память Colab. Можно использовать одну из этих или поискать что-то другое до 7B включительно:\n",
    "      * [Qwen/Qwen3-4B-Instruct-2507](https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507)\n",
    "      * [Qwen/Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)\n",
    "      * [unsloth/Llama-3.2-3B-Instruct](https://huggingface.co/unsloth/Llama-3.2-3B-Instruct)\n",
    "      * [t-tech/T-lite-it-1.0](https://huggingface.co/t-tech/T-lite-it-1.0) — модель, специально дообученная для русского языка\n",
    "      * *Не берите* модели с \"Thinking\" для этой задачи — они генерируют длинные цепочки мыслей перед ответом, будет работать очень долго.\n",
    "3.  **Эксперимент 1: Zero-shot.**\n",
    "      * Напишите промпт, в котором вы подаёте модели предложение и просите классифицировать его\n",
    "      * Прогоните ваши тестовые примеры через модель\n",
    "      * Распарсите ответ, достаньте оттуда метку класса в формате, который вы задали. Если модель не слушается инструкций и отвечает не так, как вы её попросили, это можно считать за ошибку\n",
    "4.  **Эксперимент 2: Few-shot.**\n",
    "      * Возьмите 5–10 примеров из трейна. Следите, чтобы там были и грамматичные, и неграмматичные предложения\n",
    "      * Включите эти примеры с правильными ответами в промпт\n",
    "      * Прогоните те же тестовые примеры\n",
    "5.  **Итоги.**\n",
    "      * Посчитайте метрики классификации (Accuracy или F1) для обоих экспериментов\n",
    "      * Выведите несколько примеров ошибочно классифицированных предложений, проанализируйте вручную. Если хотите, можно использовать столбец `error_type` в оригинальном датасете и собрать статистику, какие типы ошибок распознаются неправильно чаще, но это опционально\n",
    "      * Сделайте выводы: помог ли few-shot? Насколько вообще маленькая модель справляется с этой задачей Есть ли какие-то очевидные закономерности в ошибках модели?\n",
    "\n",
    "> **Важно:** не пытайтесь делать это задание через модели по API, оно не будет засчитано и вы можете быстро израсходовать бюджет ключей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3c50a",
   "metadata": {},
   "source": [
    "**Подсказки:**\n",
    "\n",
    "1. Не надо подавать в модель все тестовые примеры сразу, нужно по одному на каждый запрос\n",
    "2. Можно поставить очень маленькое значение параметра `max_new_tokens` — если модель не будет слушаться инструкций и начнёт писать пояснения или рассуждения, она по крайней мере быстро остановится и зря не потратит время и память\n",
    "3. В этом задании не обязательно использовать вывод в JSON, хотя можно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad70696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "033f7592",
   "metadata": {},
   "source": [
    "## Расскажите нам, что думаете об этой домашке\n",
    "\n",
    "Как вам задания? Насколько интересно? Насколько сложно? Что хотелось бы добавить, изменить или убрать? Только честно! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345543c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
